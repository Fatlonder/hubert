{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "import yaml\n",
    "from utils.config import HubertTrainingConfig\n",
    "from hubert import HubertModel\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "REF_BATCH = 512\n",
    "BATCH = 128\n",
    "\n",
    "WORKERS = 4\n",
    "EPOCHS = 1\n",
    "BLOCK = 128\n",
    "WARMUP = 20\n",
    "\n",
    "with open('/workspaces/hubert/utils/hubert_config.yaml', 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "config = HubertTrainingConfig.from_dict(config_dict)\n",
    "model = HubertModel(config)\n",
    "print(f\"{config.model}\\n{model}\")\n",
    "\"\"\"\n",
    "random_sampler = RandomSampler(train_dataset)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=random_sampler,\n",
    "    batch_size=BATCH,\n",
    "    num_workers=WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(devices=1, accelerator=\"gpu\", max_epochs=EPOCHS, precision=16, log_every_n_steps=1, accumulate_grad_batches=REF_BATCH // BATCH,)\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(0.9,0.98)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.optimizer.adam_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pip==23.1.2\n",
    "!pip install datasets pydub torchaudio fairseq npy-append-array tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.hubert_data import HubertDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "train_dataset = HubertDataset(\n",
    "    manifest_path='/content/common_voice_data/train.tsv',\n",
    "    sample_rate=48000,\n",
    "    label_paths=['/content/labels/0_0_1.km'],\n",
    "    label_rates=[-1.0],\n",
    "    pad_list=[0],  # padding token index\n",
    "    eos_list=[1],  # end-of-sequence token index\n",
    "    label_processors=None,\n",
    "    max_keep_sample_size=320000,\n",
    "    min_keep_sample_size=None,\n",
    "    max_sample_size=160000,\n",
    "    pad_audio=True,\n",
    "    normalize=True,\n",
    "    store_labels=False,\n",
    "    random_crop=True,\n",
    "    single_target=True,\n",
    ")\n",
    "random_sampler = RandomSampler(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, collate_fn=train_dataset.collater, sampler=random_sampler, batch_size=2, num_workers=1, pin_memory=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in train_loader:\n",
    "  print(it)\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
