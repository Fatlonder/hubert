{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HubertConfig(_name='hubert', label_rate=100, extractor_mode='default', encoder_layers=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_attention_heads=12, activation_fn='gelu', layer_type='transformer', dropout=0.1, attention_dropout=0.1, activation_dropout=0.0, encoder_layerdrop=0.05, dropout_input=0.1, dropout_features=0.1, final_dim=256, untie_final_proj=True, layer_norm_first=False, conv_feature_layers='[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', conv_bias=False, logit_temp=0.1, target_glu=False, feature_grad_mult=0.1, mask_length=10, mask_prob=0.8, mask_selection='static', mask_other=0, no_mask_overlap=False, mask_min_space=1, mask_channel_length=64, mask_channel_prob=0.5, mask_channel_selection='static', mask_channel_other=0, no_mask_channel_overlap=False, mask_channel_min_space=1, conv_pos=95, conv_pos_groups=16, conv_pos_batch_norm=False, latent_temp=(2, 0.5, 0.999995), skip_masked=False, skip_nomask=False, checkpoint_activations=False, required_seq_len_multiple=2, depthwise_conv_kernel_size=31, attn_type='', pos_enc_type='abs', fp16=False, sample_rate=16000, apply_mask=True, layerdrop=0.1, freeze_finetune_updates=10000, pos_conv_depth=5)\n",
      "HubertModel(\n",
      "  (feature_extractor): ConvFeatureExtractionModel(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "        (3): GELU(approximate='none')\n",
      "      )\n",
      "      (1-4): 4 x Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "      (5-6): 2 x Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
      "  (dropout_input): Dropout(p=0.1, inplace=False)\n",
      "  (dropout_features): Dropout(p=0.1, inplace=False)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (pos_conv): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)\n",
      "        (1): SamePad()\n",
      "        (2): TransposeLast()\n",
      "        (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "        (4): TransposeLast()\n",
      "        (5): GELU(approximate='none')\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)\n",
      "        (1): SamePad()\n",
      "        (2): TransposeLast()\n",
      "        (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "        (4): TransposeLast()\n",
      "        (5): GELU(approximate='none')\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)\n",
      "        (1): SamePad()\n",
      "        (2): TransposeLast()\n",
      "        (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "        (4): TransposeLast()\n",
      "        (5): GELU(approximate='none')\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)\n",
      "        (1): SamePad()\n",
      "        (2): TransposeLast()\n",
      "        (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "        (4): TransposeLast()\n",
      "        (5): GELU(approximate='none')\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16)\n",
      "        (1): SamePad()\n",
      "        (2): TransposeLast()\n",
      "        (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False)\n",
      "        (4): TransposeLast()\n",
      "        (5): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x TransformerSentenceEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (final_proj): Linear(in_features=768, out_features=256, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from utils.config import HubertTrainingConfig\n",
    "from hubert import HubertModel\n",
    "\n",
    "with open('/workspaces/hubert/utils/hubert_config.yaml', 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "config = HubertTrainingConfig.from_dict(config_dict)\n",
    "model = HubertModel(config)\n",
    "print(f\"{config.model}\\n{model}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
