{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pip==23.1.2\n",
    "!pip install datasets pydub torchaudio fairseq\n",
    "!sudo apt install libsox-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yt-dlp/yt-dlp.git yt-dlp\n",
    "%cd yt-dlp\n",
    "!make yt-dlp\n",
    "!sudo cp yt-dlp /usr/local/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = \"\"\"\n",
    "# Netscape HTTP Cookie File\n",
    "# This file is generated by youtube-dl.  Do not edit.\n",
    "\n",
    ".google.com\tTRUE\t/\tTRUE\t1748961130\tAEC\twwwwwww\n",
    ".youtube.com\tTRUE\t/\tTRUE\t1733432221\tGPS\t1\n",
    ".youtube.com\tTRUE\t/\tTRUE\t1749240520\tNID\twwwwwww\n",
    ".youtube.com\tTRUE\t/\tTRUE\t1767989250\tPREF\ttz=wwwww\n",
    ".youtube.com\tTRUE\t/\tTRUE\t0\tSOCS\tCAI\n",
    ".youtube.com\tTRUE\t/\tTRUE\t1748960410\tVISITOR_INFO1_LIVE\twwwww\n",
    ".youtube.com\tTRUE\t/\tTRUE\t1748960410\tVISITOR_PRIVACY_METADATA\twwwww\n",
    ".youtube.com\tTRUE\t/\tTRUE\t0\tYSC\twwwww\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_download_extended = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import yt_dlp\n",
    "\n",
    "#    'format': '(bestvideo[width>=1080][ext=mp4]/bestvideo)+bestaudio/best', #Ensures best settings\n",
    "ydl_opts = {\n",
    "    'format': 'best', #Ensures best settings\n",
    "    'postprocessors': [\n",
    "      {\n",
    "          'key': 'FFmpegExtractAudio',\n",
    "          'preferredcodec': 'wav',\n",
    "          'preferredquality': '320',\n",
    "          'nopostoverwrites': True,  # Prevents overwriting files that already exist\n",
    "      }\n",
    "    ],\n",
    "    \"outtmpl\":'/content/ytm/%(title)s.%(ext)s',\n",
    "    'cookiefile': '/content/cookies.txt',\n",
    "    \"retries\": 10,\n",
    "    \"fragment_retries\": 10,\n",
    "    \"sleep_interval\": 5,\n",
    "    \"http_headers\": {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    },}\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(files_to_download_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from fairseq.data.audio.audio_utils import get_features_or_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wav_meta_tsv(audio_dir, output_dir):\n",
    "    with open(output_dir, \"a\") as f:\n",
    "        for filename in os.listdir(audio_dir):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                audio_path = os.path.join(audio_dir, filename)\n",
    "                try:\n",
    "                    audio = AudioSegment.from_wav(audio_path)\n",
    "                    duration = len(audio) / 1000.0  # Convert milliseconds to seconds\n",
    "                    f.write(f\"{audio_path}\\t{duration}\\t{int(time.time() + duration)}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {audio_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfccFeatureReader(object):\n",
    "    def __init__(self, sample_rate):\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def read_audio_mp3(self, path):\n",
    "      audio = AudioSegment.from_mp3(path)  # Load MP3 file\n",
    "      audio = audio.set_channels(1)  # mono\n",
    "      audio = audio.set_frame_rate(self.sample_rate)\n",
    "      #waveform = np.array(audio.get_array_of_samples())\n",
    "      wav_path = audio.export(f\"{path}.wav\", format=\"wav\").name\n",
    "      return wav_path\n",
    "\n",
    "    def read_audio(self, path, ref_len=None):\n",
    "        #wav_path = self.read_audio_mp3(path)\n",
    "        wav_path = path\n",
    "        wav = get_features_or_waveform(wav_path, need_waveform=True, use_sample_rate=self.sample_rate)\n",
    "        if ref_len is not None and abs(ref_len - len(wav)) > 160:\n",
    "            print(f\"ref {ref_len} != read {len(wav)}\")\n",
    "        return wav\n",
    "\n",
    "    def get_feats(self, path, ref_len=None):\n",
    "        x = self.read_audio(path, ref_len=ref_len)\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(x).float()\n",
    "            x = x.view(1, -1)\n",
    "\n",
    "            mfccs = torchaudio.compliance.kaldi.mfcc(\n",
    "                waveform=x,\n",
    "                sample_frequency=self.sample_rate,\n",
    "                use_energy=False,\n",
    "            )  # (time, freq)\n",
    "            mfccs = mfccs.transpose(0, 1)  # (freq, time)\n",
    "            deltas = torchaudio.functional.compute_deltas(mfccs)\n",
    "            ddeltas = torchaudio.functional.compute_deltas(deltas)\n",
    "            concat = torch.cat([mfccs, deltas, ddeltas], dim=0)\n",
    "            concat = concat.transpose(0, 1).contiguous()  # (freq, time)\n",
    "            return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_iterator(tsv):\n",
    "    with open(tsv, \"r\") as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "        def iterate():\n",
    "            for line in lines:\n",
    "                subpath, nsample, idx_id = line.split(\"\\t\")\n",
    "                yield f\"{subpath}\", int(float(nsample)), idx_id\n",
    "    return iterate, len(lines)\n",
    "\n",
    "def wav_to_mfcc(reader, generator, num, feat_dir):\n",
    "    iterator = generator()\n",
    "    parquet_writer = None\n",
    "    features = []\n",
    "    lengths = []\n",
    "    idx_val = []\n",
    "\n",
    "    feat_path = f\"{feat_dir}mfcc_features_1.parquet\"\n",
    "\n",
    "    for path, nsample, idx_id in tqdm.tqdm(iterator, total=num):\n",
    "        feat = reader.get_feats(path, nsample)\n",
    "        feat_np = feat.cpu().numpy()\n",
    "        features.append(feat_np)\n",
    "        lengths.append(len(feat))\n",
    "        idx_val.append(idx_id)\n",
    "\n",
    "    table = pa.table({\n",
    "        'features': pa.array(features, type=pa.list_(pa.float64())),\n",
    "        'duration_sec': pa.array(lengths, type=pa.int32()),\n",
    "        'indx_id':  pa.array(lengths, type=pa.int32()),\n",
    "      })\n",
    "    parquet_writer = pq.ParquetWriter(feat_path, table.schema)\n",
    "    parquet_writer.write_table(table)\n",
    "\n",
    "    if parquet_writer is not None:\n",
    "        parquet_writer.close()\n",
    "\n",
    "def dump_duration(generator, num):\n",
    "    iterator = generator()\n",
    "    duration = []\n",
    "    for path, nsample, idx_id in tqdm.tqdm(iterator, total=num):\n",
    "        duration.append(nsample)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_file_name(audio_meta_file, correct_file_names_str, output_meta_csv_path):\n",
    "    def parse_file_name_lines(meta_row_string):\n",
    "        lines = meta_row_string.strip().split(\"\\n\")\n",
    "        parsed_lines = [line.split(\"\\t\") for line in lines]\n",
    "        return parsed_lines\n",
    "\n",
    "    file_name_mapping = {}\n",
    "\n",
    "    with open(audio_meta_file, mode='r') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter='\\t')  # Use tab delimiter\n",
    "        for row in csv_reader:\n",
    "            csv_file_name, csv_time_duration, *_ = row  # Handle rows with more than 2 columns\n",
    "            file_name_mapping[float(csv_time_duration)] = csv_file_name\n",
    "\n",
    "    def save_updated_csv(parsed_lines, file_name_mapping, output_file):\n",
    "        with open(output_file, mode='w', newline='') as out_csv:\n",
    "            csv_writer = csv.writer(out_csv, delimiter='\\t')\n",
    "            for file_name, time_duration, identifier in parsed_lines:\n",
    "                time_duration_float = float(time_duration)\n",
    "                updated_file_name = file_name_mapping.get(time_duration_float, file_name)\n",
    "                csv_writer.writerow([updated_file_name, time_duration, identifier])\n",
    "\n",
    "    parsed_lines = parse_file_name_lines(correct_file_names_str)\n",
    "    save_updated_csv(parsed_lines, file_name_mapping, output_meta_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_update_mono_channel(tsv_file_path, target_sample_rate):\n",
    "    data = pd.read_csv(tsv_file_path, sep=\"\\t\", header=None)\n",
    "    file_paths = data[0]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            audio, sample_rate = sf.read(file_path)\n",
    "\n",
    "            if audio.ndim == 1:\n",
    "                audio = audio[:, None]  # Convert to 2D (n_samples, 1)\n",
    "                audio = audio.repeat(2, axis=1)  # Duplicate channel to make it stereo\n",
    "\n",
    "            resampled_audio = librosa.resample(y=audio.T if audio.ndim > 1 else audio, \n",
    "                                            orig_sr=sample_rate, \n",
    "                                            target_sr=target_sample_rate)\n",
    "            \n",
    "            if audio.ndim > 1:\n",
    "                resampled_audio = resampled_audio.T\n",
    "\n",
    "            sf.write(file_path, resampled_audio, target_sample_rate)\n",
    "            print(f\"Processed and saved: {file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waw_to_parquet(wav_meta_file_path, target_sample_rate=16000):\n",
    "    data = []\n",
    "    audio_files = []\n",
    "\n",
    "    with open(wav_meta_file_path, \"r\", encoding=\"utf-8\") as tsv_file:\n",
    "        reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            file_path, duration, idx_key = row\n",
    "            audio_files.append({\n",
    "                \"file_path\": file_path,\n",
    "                \"duration_sec\": float(duration),\n",
    "                \"indx_id\": idx_key\n",
    "            })\n",
    "\n",
    "    for audio_info in audio_files:\n",
    "        file_path = audio_info[\"file_path\"]\n",
    "        idx_key = audio_info[\"indx_id\"]\n",
    "        duration_sec = audio_info[\"duration_sec\"]\n",
    "\n",
    "        try:\n",
    "            audio, sample_rate = sf.read(file_path)\n",
    "            audio_features = librosa.resample(y=audio.T if audio.ndim > 1 else audio, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
    "            data.append({\n",
    "                \"wav_features\": audio_features.tolist(),\n",
    "                \"indx_id\": idx_key,\n",
    "                \"duration_sec\": duration_sec\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file_path = \"/content/voice_meta/train.tsv\"\n",
    "audio_dir = \"/content/ytm\"  # Directory containing wav files\n",
    "dump_mfcc_feat_dir = \"/content/km/\"\n",
    "sample_rate = 16000\n",
    "reader = MfccFeatureReader(sample_rate)\n",
    "\n",
    "create_wav_meta_tsv(audio_dir, meta_file_path)\n",
    "generator, num = get_path_iterator(f\"{meta_file_path}\")\n",
    "wav_to_mfcc(reader, generator, num, dump_mfcc_feat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, num = get_path_iterator(f\"{meta_file_path}\")\n",
    "duration_lst = dump_duration(generator, num)\n",
    "print(f\"{sum(duration_lst)/(60*60)} hrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parquet_file = \"wav_features_s1.parquet\"\n",
    "audio_meta_file = \"/content/voice_meta/train.tsv\"\n",
    "correct_name_str = \"\"\"audio.wav 7455    11114445\"\"\" # or read meta_file_path\n",
    "output_meta_csv_path = \"wav_meta_file_s1.tsv\"\n",
    "target_sample_rate = 16000\n",
    "\n",
    "fix_file_name(audio_meta_file, correct_name_str, output_meta_csv_path)\n",
    "resample_update_mono_channel(output_meta_csv_path, target_sample_rate)\n",
    "df = waw_to_parquet(output_meta_csv_path, target_sample_rate)\n",
    "df.to_parquet(output_parquet_file, engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/content/km/mfcc_features_1.parquet\",\n",
    "    path_in_repo=\"mfcc_features_s1.parquet\",\n",
    "    repo_id=\"\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
